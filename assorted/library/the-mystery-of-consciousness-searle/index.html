<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <style rel="stylesheet">
    body{
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
      margin:40px auto;
      max-width:650px;
      font-size:18px;
      padding:0 10px;
      color: #333;
      text-align: justify;
    }
    pre {
      background: #f4f4f4;
      border: 1px solid #ddd;
      border-left: 3px solid #000;
      color: #777;
      page-break-inside: avoid;
      font-family: monospace;
      font-size: 15px;
      max-width: 100%;
      overflow: auto;
      padding: 1em 1.5em;
      display: block;
      word-wrap: break-word;
    }
    a {
      color: #1976d2;
      text-decoration: none;
      border-bottom: 1px solid;
    }
    img {
      max-width: 100%;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    li {
      margin-bottom: 5px;
    }
    :not(pre) > code {
      background-color: #dfdfdf;
      padding-right: 0.2em;
      padding-left: 0.2em;
      border-radius: 3px;
    }
  </style>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<p>January 30th, 2021</p>
<h1>Review</h1>
<p><img src="the-mystery-of-consciousness-searle.jpg" alt="the-mystery-of-consciousness-searle"></p>
<h2>Computational Theory of Mind</h2>
<p>From the mid 20th century onwards, cognitive science has been blasted with
theories speculating that computers would soon create - or simulate -
consciousness.</p>
<p>Advances in computer science were enormous, and the hype of being able to
simulate a brain within a computer was expected to be nothing but a natural
flow-on effect of such advances.</p>
<p>That is what most people thought. The 'Chinese Room Argument' (1980) was
nothing but a bucket of cold water waiting to hit those very same cognitive
scientists hyping about computer-based consciousness simulation.</p>
<p>Although this book is not about the 'Chinese Room Argument' itself, it is
useful to understand how it works for the purposes of the discussion that will
follow.</p>
<h2>The Chinese Room Argument</h2>
<p>The Chinese Room Argument goes as follows:</p>
<ul>
<li>Imagine you are a native English speaker (or whatever any other language for
that sake), but you don't know anything about Chinese.</li>
<li>You are locked in a room with many Chinese symbols.</li>
<li>In this room, there is a book that shows you how to use these symbols</li>
<li>Now imagine that outside of this room, some Chinese people are sending
writing sentences in Chinese.</li>
<li>There is a little hole inside one of the walls of that room that allows those
written sentences to be sent to the inside.</li>
<li>By using the instructions book, you are able to compare the Chinese symbols
in the input, and send back correct answers back through the hole in the
wall.</li>
<li>This book allows you to pass the Turing Test for understanding Chinese, even
though you don't understand a single word of Chinese.</li>
</ul>
<p>In 2010, Searle refreshes the argument and writes the following conclusion:</p>
<blockquote>
<p>I demonstrated years ago with the so-called Chinese Room Argument that the
implementation of the computer program is not by itself sufficient for
consciousness or intentionality (Searle 1980). Computation is defined purely
formally or syntactically, whereas minds have actual mental or semantic
contents, and we cannot get from syntactical to the semantic just by having the
syntactical operations and nothing else. To put this point slightly more
technically, the notion “same implemented program” defines an equivalence class
that is specified independently of any specific physical realization. But such
a specification necessarily leaves out the biologically specific powers of the
brain to cause cognitive processes. A system, me, for example, would not
acquire an understanding of Chinese just by going through the steps of a
computer program that simulated the behaviour of a Chinese speaker.</p>
</blockquote>
<p>This is particularly interesting because if we try to simulate a brain based on
behaviour, i.e, by creating a computer software that behaves like a conscious
human, it does not follow that this software will be 'conscious'.</p>
<h2>Ok, now we can properly start the book review</h2>
<p>The book goes on as Searle attempts to expose the fallacies of different
models of consciousness. Not only the computation view described above, but
also including models based on dualist views (mental world vs physical world),
materialist views, and even a model that denies consciousness itself.</p>
<p>In the book, each chapter is marked by a different discussion about one model.
Those discussions often come accompanied by letters containing the exchange
between Searle and the author of that model, as this author tries to defend his
position.</p>
<p>Those letters are often hilarious as both ends are 'academically offensive'
towards each other, but they are also productive and interesting as the reader
can understand better what the corner-cases and anomalies of a certain
consciousness model are.</p>
<p>The book ends with Searle's account of which direction should be taken if we
want to improve our knowledge about consciousness. He's obviously advocating
for a deeper understanding of the biological phenomena that happens in the
brain. As much as &quot;digestion&quot; is a biological phenomena, and can be studied as
a process that culminates in absorption of nutrients, the brain can be studied
as a biological machine that develops sentience.</p>
</body>
</html>
